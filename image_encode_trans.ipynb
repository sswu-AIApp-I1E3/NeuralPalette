{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 기본 세팅"
      ],
      "metadata": {
        "id": "-yzy1h76WSVa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ek0CoJ191HO_",
        "outputId": "3c291004-4d31-4eab-f072-717996a4f28d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 필요한 라이브러리 임포트\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import random\n",
        "import shutil\n",
        "from google.colab import files\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.utils.data.dataloader import default_collate\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "qzS1f6uJscVs"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 환경 세팅\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Device: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQzPulduuoSm",
        "outputId": "78e2ff61-8164-4beb-a02a-ca9cf6a0669f"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모든 경로는 본인 환경에 맞춰 수정!"
      ],
      "metadata": {
        "id": "Wc0kQOx8UlA-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 이미지 데이터셋 가져오기"
      ],
      "metadata": {
        "id": "RfmQ4qciWVIl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## coco(content)\n",
        "- 코랩 상에서 불러옴"
      ],
      "metadata": {
        "id": "IqYm-iezWbsY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # 1. 다운로드 디렉토리 설정\n",
        "# coco_drive_path = '/content/drive/MyDrive/Colab Notebooks/AIApp/images/coco'\n",
        "# coco_local_path = '/content/test2017'\n",
        "# os.makedirs(coco_drive_path, exist_ok=True)\n",
        "\n",
        "# # 2. test2017.zip 다운로드\n",
        "# !wget -O /content/test2017.zip http://images.cocodataset.org/zips/test2017.zip\n",
        "# print(\"이미지 zip 다운로드 완료됨\")\n",
        "\n",
        "# # 3. 압축 해제 (unzip 사용)\n",
        "# print(\"압축 해제 중...\")\n",
        "# !unzip -q /content/test2017.zip -d /content/\n",
        "# print(\"압축 해제 완료\")\n",
        "\n",
        "# # 4. 이미지 파일 리스트 가져오기\n",
        "# image_extensions = ('.jpg', '.jpeg', '.png')\n",
        "# all_images = [f for f in os.listdir(coco_local_path) if f.lower().endswith(image_extensions)]\n",
        "# print(f\"전체 이미지 수: {len(all_images)}장\")\n",
        "\n",
        "# # 5. 랜덤하게 25,000장 추출\n",
        "# random.seed(42)\n",
        "# selected_images = random.sample(all_images, 25000)\n",
        "# print(\"25,000장 랜덤 추출 완료\")\n",
        "\n",
        "# # 6. 선택한 이미지만 coco_drive_path에 복사\n",
        "# for i, filename in enumerate(selected_images):\n",
        "#     src_path = os.path.join(coco_local_path, filename)\n",
        "#     dst_path = os.path.join(coco_drive_path, filename)\n",
        "#     shutil.copy2(src_path, dst_path)\n",
        "#     if (i+1) % 5000 == 0:\n",
        "#         print(f\"  ... {i+1}장 복사됨\")\n",
        "# print(\"이미지 복사 완료\")\n",
        "\n",
        "# # 7. 원본 압축파일과 전체 해제 폴더 제거\n",
        "# os.remove('/content/test2017.zip')\n",
        "# shutil.rmtree(coco_local_path)\n",
        "# print(\"불필요한 파일 삭제 완료\")\n",
        "\n",
        "# # 8. 완료 메시지\n",
        "# print(f\"최종 저장 경로: {coco_drive_path}\")\n",
        "# final_images = [f for f in os.listdir(coco_drive_path) if f.lower().endswith(image_extensions)]\n",
        "# print(f\"최종 저장된 이미지 수: {len(final_images)}장\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6Q0N3X6WQZN",
        "outputId": "1098de22-c47b-49e6-dff0-955097a6307d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-05-20 20:35:29--  http://images.cocodataset.org/zips/test2017.zip\n",
            "Resolving images.cocodataset.org (images.cocodataset.org)... 54.231.132.57, 3.5.24.118, 52.216.221.241, ...\n",
            "Connecting to images.cocodataset.org (images.cocodataset.org)|54.231.132.57|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6646970404 (6.2G) [application/zip]\n",
            "Saving to: ‘/content/test2017.zip’\n",
            "\n",
            "/content/test2017.z 100%[===================>]   6.19G  56.4MB/s    in 1m 55s  \n",
            "\n",
            "2025-05-20 20:37:24 (55.1 MB/s) - ‘/content/test2017.zip’ saved [6646970404/6646970404]\n",
            "\n",
            "이미지 zip 다운로드 완료됨\n",
            "압축 해제 중...\n",
            "압축 해제 완료\n",
            "전체 이미지 수: 40670장\n",
            "25,000장 랜덤 추출 완료\n",
            "  ... 5000장 복사됨\n",
            "  ... 10000장 복사됨\n",
            "  ... 15000장 복사됨\n",
            "  ... 20000장 복사됨\n",
            "  ... 25000장 복사됨\n",
            "이미지 복사 완료\n",
            "불필요한 파일 삭제 완료\n",
            "최종 저장 경로: /content/drive/MyDrive/Colab Notebooks/AIApp/images/coco\n",
            "최종 저장된 이미지 수: 25000장\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## wikiart(style)\n",
        "- https://www.kaggle.com/datasets/trungit/wikiart25k 에서 데이터셋 다운 받아 txt 파일 제거 후 압축본 구글 드라이브에 업로드 한 뒤 실행"
      ],
      "metadata": {
        "id": "IFKMFpK4Wd4e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # zip 파일 압축 해제\n",
        "# %cd /content/drive/MyDrive/Colab Notebooks/AIApp/images\n",
        "# !unzip -qq \"/content/drive/MyDrive/Colab Notebooks/AIApp/wikiart.zip\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HsKkP7P_B9y-",
        "outputId": "fb9ca562-c753-4624-a0f9-aa64c37ac7d7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/AIApp/images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # 압축이 풀린 최상위 폴더 경로\n",
        "# root_path = \"/content/drive/MyDrive/Colab Notebooks/AIApp/images/wikiart\"\n",
        "\n",
        "# # 이미지 확장자 목록\n",
        "# image_extensions = ('.jpg', '.jpeg', '.png')\n",
        "\n",
        "# # 이미지 수 카운트\n",
        "# image_count = 0\n",
        "# for root, dirs, files in os.walk(root_path):\n",
        "#     for file in files:\n",
        "#         if file.lower().endswith(image_extensions):\n",
        "#             image_count += 1\n",
        "\n",
        "# print(f\"총 이미지 수: {image_count}장\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X6UwxpEDRmql",
        "outputId": "da6cd747-45d1-4a1f-ac38-09a935797035"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🖼️ 총 이미지 수: 25000장\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# VGG 인코더"
      ],
      "metadata": {
        "id": "_u1BN98RTGMG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# VGG-19 pretrained 모델에서 features만 가져오기\n",
        "vgg = models.vgg19(pretrained=True).features\n",
        "\n",
        "# relu1_1 ~ relu4_1까지 레이어 분할\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, encoder):\n",
        "        super(Net, self).__init__()\n",
        "        enc_layers = list(encoder.children())\n",
        "\n",
        "        # relu1_1, relu2_1, relu3_1, relu4_1까지만 사용\n",
        "        self.enc_1 = nn.Sequential(*enc_layers[:4])    # input -> relu1_1\n",
        "        self.enc_2 = nn.Sequential(*enc_layers[4:11])  # relu1_1 -> relu2_1\n",
        "        self.enc_3 = nn.Sequential(*enc_layers[11:18]) # relu2_1 -> relu3_1\n",
        "        self.enc_4 = nn.Sequential(*enc_layers[18:31]) # relu3_1 -> relu4_1\n",
        "\n",
        "        # encoder 파라미터 고정\n",
        "        for name in ['enc_1', 'enc_2', 'enc_3', 'enc_4']:\n",
        "            for param in getattr(self, name).parameters():\n",
        "                param.requires_grad = False\n",
        "\n",
        "    # 중간 결과들 (relu1_1 ~ relu4_1) 반환\n",
        "    def encode_with_intermediate(self, input):\n",
        "        results = [input]\n",
        "        for i in range(4):\n",
        "            func = getattr(self, f'enc_{i + 1}')\n",
        "            results.append(func(results[-1]))\n",
        "        return results[1:]  # input 제외한 결과만 반환\n",
        "\n",
        "    # relu4_1 결과만 반환\n",
        "    def encode(self, input):\n",
        "        for i in range(4):\n",
        "            input = getattr(self, f'enc_{i + 1}')(input)\n",
        "        return input\n",
        "\n",
        "# 네트워크 객체 생성\n",
        "net = Net(vgg).to('cuda' if torch.cuda.is_available() else 'cpu')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BNyUg_WHV_T8",
        "outputId": "b6866dcb-cde4-4dec-8828-8dd38a01393d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\" to /root/.cache/torch/hub/checkpoints/vgg19-dcbb9e9d.pth\n",
            "100%|██████████| 548M/548M [00:08<00:00, 69.2MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 이미지 전처리\n",
        "\n",
        "# 짧은 변 길이 변경\n",
        "class ResizeShortSide:\n",
        "    def __init__(self, size):\n",
        "        self.size = size\n",
        "\n",
        "    def __call__(self, img):\n",
        "        w, h = img.size\n",
        "        if w < h:\n",
        "            new_w = self.size\n",
        "            new_h = int(h * self.size / w)\n",
        "        else:\n",
        "            new_h = self.size\n",
        "            new_w = int(w * self.size / h)\n",
        "        return img.resize((new_w, new_h), Image.BICUBIC)\n",
        "\n",
        "# 전체 전처리\n",
        "vgg_transform = transforms.Compose([\n",
        "    ResizeShortSide(512),\n",
        "    transforms.RandomCrop(256),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std =[0.229, 0.224, 0.225])\n",
        "])\n"
      ],
      "metadata": {
        "id": "kuH5afj9a2Bb"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 특징 추출\n",
        "\n",
        "# 이미지 파일 확인\n",
        "def is_image_file(filename):\n",
        "    return filename.lower().endswith(('jpg', 'jpeg', 'png'))\n",
        "\n",
        "# 하위 폴더 확인\n",
        "class ImageFolderDataset(Dataset):\n",
        "    def __init__(self, folder_path, transform, has_subfolders=True):\n",
        "        self.transform = transform\n",
        "        self.image_paths = []\n",
        "\n",
        "        if has_subfolders:\n",
        "            subfolders = [os.path.join(folder_path, d)\n",
        "                          for d in os.listdir(folder_path)\n",
        "                          if os.path.isdir(os.path.join(folder_path, d))]\n",
        "        else:\n",
        "            subfolders = [folder_path]\n",
        "\n",
        "        for subfolder in subfolders:\n",
        "            for fname in os.listdir(subfolder):\n",
        "                if is_image_file(fname):\n",
        "                    self.image_paths.append(os.path.join(subfolder, fname))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        path = self.image_paths[idx]\n",
        "        try:\n",
        "            image = Image.open(path).convert('RGB')\n",
        "            tensor = self.transform(image)\n",
        "            return tensor, path\n",
        "        except Exception as e:\n",
        "            print(f\"[오류] 이미지 로딩 실패: {path}, 오류: {e}\")\n",
        "            return None  # collate_fn에서 필터링됨\n",
        "\n",
        "# collate_fn 정의 (예외 이미지 무시)\n",
        "def safe_collate(batch):\n",
        "    batch = [b for b in batch if b is not None]\n",
        "    if not batch:\n",
        "        return None\n",
        "    return default_collate(batch)\n",
        "\n",
        "# 특징 추출 함수 (배치 기반)\n",
        "def extract_features_batch(folder_path, transform, has_subfolders=True, batch_size=32, num_workers=2):\n",
        "    dataset = ImageFolderDataset(folder_path, transform, has_subfolders)\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False,\n",
        "                            num_workers=num_workers, collate_fn=safe_collate)\n",
        "\n",
        "    features = []\n",
        "    paths = []\n",
        "\n",
        "    for batch in tqdm(dataloader, desc=f\"Extracting features from {os.path.basename(folder_path)}\"):\n",
        "        if batch is None:\n",
        "            continue\n",
        "        inputs, img_paths = batch\n",
        "        inputs = inputs.to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            batch_features = net.encode(inputs)\n",
        "\n",
        "        features.extend(batch_features.cpu())\n",
        "        paths.extend(img_paths)\n",
        "\n",
        "    return features, paths"
      ],
      "metadata": {
        "id": "dDC-kgcHXhdq"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 테스트용 coco_test 만들기\n",
        "coco_dir = '/content/drive/MyDrive/Colab Notebooks/AIApp/images/coco'\n",
        "coco_test_dir = '/content/drive/MyDrive/Colab Notebooks/AIApp/images/coco_test'\n",
        "\n",
        "# os.makedirs(coco_test_dir, exist_ok=True)\n",
        "\n",
        "# image_files = sorted([\n",
        "#     f for f in os.listdir(coco_dir)\n",
        "#     if f.lower().endswith(('.jpg', '.jpeg', '.png'))\n",
        "# ])[:32]\n",
        "\n",
        "# # 복사 실행\n",
        "# for fname in image_files:\n",
        "#     src_path = os.path.join(coco_dir, fname)\n",
        "#     dst_path = os.path.join(coco_test_dir, fname)\n",
        "#     shutil.copy2(src_path, dst_path)\n",
        "\n",
        "# print(f\"{len(image_files)}개 이미지가 {coco_test_dir}로 복사되었습니다.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TGIhllqMsFo0",
        "outputId": "aa8af19e-fcba-4f43-de16-c99716cb3819"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32개 이미지가 /content/drive/MyDrive/Colab Notebooks/AIApp/images/coco_test로 복사되었습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 인코딩(테스트용)\n",
        "coco_test_features, coco_test_paths = extract_features_batch(coco_test_dir, vgg_transform, has_subfolders=False)\n",
        "coco_test_features[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NtjkS2pZTNS6",
        "outputId": "4643e88e-b5d7-48f2-d6e6-407c28b72cf8"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting features from coco_test: 100%|██████████| 1/1 [00:36<00:00, 36.55s/it]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([512, 16, 16])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # 인코딩(실제 사용) - 엄청 오래 걸림\n",
        "# coco_dir = '/content/drive/MyDrive/Colab Notebooks/AIApp/images/coco'\n",
        "# wikiart_dir = '/content/drive/MyDrive/Colab Notebooks/AIApp/images/wikiart'\n",
        "\n",
        "# coco_features, coco_paths = extract_features_batch(coco_dir, vgg_transform, has_subfolders=False)\n",
        "# print(\"coco 인코딩 끝\")\n",
        "# wikiart_features, wikiart_paths = extract_features_batch(wikiart_dir, vgg_transform, has_subfolders=True)\n",
        "# print(\"wikiart 인코딩 끝\")\n"
      ],
      "metadata": {
        "id": "rc1RAmKWVkSB"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 텍스트 피쳐 변환"
      ],
      "metadata": {
        "id": "x3nI6CE_clNz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 정의 및 가중치 불러오기\n",
        "num_classes = 4  # 감정 클래스 수\n",
        "# image_dir = '/content/drive/MyDrive/Colab Notebooks/AIApp/images/coco_test' # 테스트용\n",
        "image_dir = '/content/drive/MyDrive/Colab Notebooks/AIApp/images/coco' # 실제 사용\n",
        "\n",
        "# 모델 정의 (학습 당시와 동일하게)\n",
        "model = models.resnet18(pretrained=False)\n",
        "in_features = model.fc.in_features\n",
        "model.fc = nn.Sequential(\n",
        "    nn.Dropout(0.3),\n",
        "    nn.Linear(in_features, num_classes)\n",
        ")\n",
        "model.load_state_dict(torch.load('/content/drive/MyDrive/Colab Notebooks/AIApp/best_emotion_model_0520.pth',\n",
        "                                 map_location=torch.device('cpu'))) # 원래 gpu로 불러와야되는데 지금 gpu 못 써서 임시로 cpu\n",
        "model = model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# 전처리 정의\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rd_Q1Lqe1HSp",
        "outputId": "7ac2b5e8-fe71-4cda-98f5-d14f20c68a71"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 이미지 예측하여 label_idx 추출\n",
        "predicted_indices = []\n",
        "\n",
        "image_paths = [os.path.join(image_dir, fname) for fname in os.listdir(image_dir)\n",
        "               if fname.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
        "\n",
        "for path in tqdm(image_paths):\n",
        "    image = Image.open(path).convert('RGB')\n",
        "    image = transform(image).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model(image)\n",
        "        _, pred = torch.max(output, 1)\n",
        "        predicted_indices.append(pred.item())\n",
        "\n",
        "preds_tensor = torch.tensor(predicted_indices)\n",
        "preds_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LPn9-epDDGeP",
        "outputId": "33436054-74f1-433a-e3a5-3727692fb5d7"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 25000/25000 [1:03:21<00:00,  6.58it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([3, 2, 2,  ..., 2, 1, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 임베딩, 선형 변환\n",
        "embedding_dim = 512\n",
        "\n",
        "# 임베딩 & 선형변환 정의\n",
        "class_embedding = nn.Embedding(num_classes, embedding_dim)\n",
        "linear = nn.Linear(embedding_dim, 512)\n",
        "\n",
        "# GPU에 올리기 (선택사항)\n",
        "class_embedding = class_embedding.to(device)\n",
        "linear = linear.to(device)\n",
        "\n",
        "# 변환 수행\n",
        "embedded = class_embedding(preds_tensor.to(device))\n",
        "final_output = linear(embedded)\n"
      ],
      "metadata": {
        "id": "cdXFQk45DOUl"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4Fv5qCvTHVHS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}