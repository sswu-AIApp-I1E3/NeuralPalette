{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ê¸°ë³¸ ì„¸íŒ…"
      ],
      "metadata": {
        "id": "-yzy1h76WSVa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ek0CoJ191HO_",
        "outputId": "3c291004-4d31-4eab-f072-717996a4f28d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import random\n",
        "import shutil\n",
        "from google.colab import files\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.utils.data.dataloader import default_collate\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "qzS1f6uJscVs"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# í™˜ê²½ ì„¸íŒ…\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Device: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQzPulduuoSm",
        "outputId": "78e2ff61-8164-4beb-a02a-ca9cf6a0669f"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ëª¨ë“  ê²½ë¡œëŠ” ë³¸ì¸ í™˜ê²½ì— ë§ì¶° ìˆ˜ì •!"
      ],
      "metadata": {
        "id": "Wc0kQOx8UlA-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ì´ë¯¸ì§€ ë°ì´í„°ì…‹ ê°€ì ¸ì˜¤ê¸°"
      ],
      "metadata": {
        "id": "RfmQ4qciWVIl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## coco(content)\n",
        "- ì½”ë© ìƒì—ì„œ ë¶ˆëŸ¬ì˜´"
      ],
      "metadata": {
        "id": "IqYm-iezWbsY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # 1. ë‹¤ìš´ë¡œë“œ ë””ë ‰í† ë¦¬ ì„¤ì •\n",
        "# coco_drive_path = '/content/drive/MyDrive/Colab Notebooks/AIApp/images/coco'\n",
        "# coco_local_path = '/content/test2017'\n",
        "# os.makedirs(coco_drive_path, exist_ok=True)\n",
        "\n",
        "# # 2. test2017.zip ë‹¤ìš´ë¡œë“œ\n",
        "# !wget -O /content/test2017.zip http://images.cocodataset.org/zips/test2017.zip\n",
        "# print(\"ì´ë¯¸ì§€ zip ë‹¤ìš´ë¡œë“œ ì™„ë£Œë¨\")\n",
        "\n",
        "# # 3. ì••ì¶• í•´ì œ (unzip ì‚¬ìš©)\n",
        "# print(\"ì••ì¶• í•´ì œ ì¤‘...\")\n",
        "# !unzip -q /content/test2017.zip -d /content/\n",
        "# print(\"ì••ì¶• í•´ì œ ì™„ë£Œ\")\n",
        "\n",
        "# # 4. ì´ë¯¸ì§€ íŒŒì¼ ë¦¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°\n",
        "# image_extensions = ('.jpg', '.jpeg', '.png')\n",
        "# all_images = [f for f in os.listdir(coco_local_path) if f.lower().endswith(image_extensions)]\n",
        "# print(f\"ì „ì²´ ì´ë¯¸ì§€ ìˆ˜: {len(all_images)}ì¥\")\n",
        "\n",
        "# # 5. ëœë¤í•˜ê²Œ 25,000ì¥ ì¶”ì¶œ\n",
        "# random.seed(42)\n",
        "# selected_images = random.sample(all_images, 25000)\n",
        "# print(\"25,000ì¥ ëœë¤ ì¶”ì¶œ ì™„ë£Œ\")\n",
        "\n",
        "# # 6. ì„ íƒí•œ ì´ë¯¸ì§€ë§Œ coco_drive_pathì— ë³µì‚¬\n",
        "# for i, filename in enumerate(selected_images):\n",
        "#     src_path = os.path.join(coco_local_path, filename)\n",
        "#     dst_path = os.path.join(coco_drive_path, filename)\n",
        "#     shutil.copy2(src_path, dst_path)\n",
        "#     if (i+1) % 5000 == 0:\n",
        "#         print(f\"  ... {i+1}ì¥ ë³µì‚¬ë¨\")\n",
        "# print(\"ì´ë¯¸ì§€ ë³µì‚¬ ì™„ë£Œ\")\n",
        "\n",
        "# # 7. ì›ë³¸ ì••ì¶•íŒŒì¼ê³¼ ì „ì²´ í•´ì œ í´ë” ì œê±°\n",
        "# os.remove('/content/test2017.zip')\n",
        "# shutil.rmtree(coco_local_path)\n",
        "# print(\"ë¶ˆí•„ìš”í•œ íŒŒì¼ ì‚­ì œ ì™„ë£Œ\")\n",
        "\n",
        "# # 8. ì™„ë£Œ ë©”ì‹œì§€\n",
        "# print(f\"ìµœì¢… ì €ì¥ ê²½ë¡œ: {coco_drive_path}\")\n",
        "# final_images = [f for f in os.listdir(coco_drive_path) if f.lower().endswith(image_extensions)]\n",
        "# print(f\"ìµœì¢… ì €ì¥ëœ ì´ë¯¸ì§€ ìˆ˜: {len(final_images)}ì¥\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6Q0N3X6WQZN",
        "outputId": "1098de22-c47b-49e6-dff0-955097a6307d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-05-20 20:35:29--  http://images.cocodataset.org/zips/test2017.zip\n",
            "Resolving images.cocodataset.org (images.cocodataset.org)... 54.231.132.57, 3.5.24.118, 52.216.221.241, ...\n",
            "Connecting to images.cocodataset.org (images.cocodataset.org)|54.231.132.57|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6646970404 (6.2G) [application/zip]\n",
            "Saving to: â€˜/content/test2017.zipâ€™\n",
            "\n",
            "/content/test2017.z 100%[===================>]   6.19G  56.4MB/s    in 1m 55s  \n",
            "\n",
            "2025-05-20 20:37:24 (55.1 MB/s) - â€˜/content/test2017.zipâ€™ saved [6646970404/6646970404]\n",
            "\n",
            "ì´ë¯¸ì§€ zip ë‹¤ìš´ë¡œë“œ ì™„ë£Œë¨\n",
            "ì••ì¶• í•´ì œ ì¤‘...\n",
            "ì••ì¶• í•´ì œ ì™„ë£Œ\n",
            "ì „ì²´ ì´ë¯¸ì§€ ìˆ˜: 40670ì¥\n",
            "25,000ì¥ ëœë¤ ì¶”ì¶œ ì™„ë£Œ\n",
            "  ... 5000ì¥ ë³µì‚¬ë¨\n",
            "  ... 10000ì¥ ë³µì‚¬ë¨\n",
            "  ... 15000ì¥ ë³µì‚¬ë¨\n",
            "  ... 20000ì¥ ë³µì‚¬ë¨\n",
            "  ... 25000ì¥ ë³µì‚¬ë¨\n",
            "ì´ë¯¸ì§€ ë³µì‚¬ ì™„ë£Œ\n",
            "ë¶ˆí•„ìš”í•œ íŒŒì¼ ì‚­ì œ ì™„ë£Œ\n",
            "ìµœì¢… ì €ì¥ ê²½ë¡œ: /content/drive/MyDrive/Colab Notebooks/AIApp/images/coco\n",
            "ìµœì¢… ì €ì¥ëœ ì´ë¯¸ì§€ ìˆ˜: 25000ì¥\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## wikiart(style)\n",
        "- https://www.kaggle.com/datasets/trungit/wikiart25k ì—ì„œ ë°ì´í„°ì…‹ ë‹¤ìš´ ë°›ì•„ txt íŒŒì¼ ì œê±° í›„ ì••ì¶•ë³¸ êµ¬ê¸€ ë“œë¼ì´ë¸Œì— ì—…ë¡œë“œ í•œ ë’¤ ì‹¤í–‰"
      ],
      "metadata": {
        "id": "IFKMFpK4Wd4e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # zip íŒŒì¼ ì••ì¶• í•´ì œ\n",
        "# %cd /content/drive/MyDrive/Colab Notebooks/AIApp/images\n",
        "# !unzip -qq \"/content/drive/MyDrive/Colab Notebooks/AIApp/wikiart.zip\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HsKkP7P_B9y-",
        "outputId": "fb9ca562-c753-4624-a0f9-aa64c37ac7d7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/AIApp/images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # ì••ì¶•ì´ í’€ë¦° ìµœìƒìœ„ í´ë” ê²½ë¡œ\n",
        "# root_path = \"/content/drive/MyDrive/Colab Notebooks/AIApp/images/wikiart\"\n",
        "\n",
        "# # ì´ë¯¸ì§€ í™•ì¥ì ëª©ë¡\n",
        "# image_extensions = ('.jpg', '.jpeg', '.png')\n",
        "\n",
        "# # ì´ë¯¸ì§€ ìˆ˜ ì¹´ìš´íŠ¸\n",
        "# image_count = 0\n",
        "# for root, dirs, files in os.walk(root_path):\n",
        "#     for file in files:\n",
        "#         if file.lower().endswith(image_extensions):\n",
        "#             image_count += 1\n",
        "\n",
        "# print(f\"ì´ ì´ë¯¸ì§€ ìˆ˜: {image_count}ì¥\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X6UwxpEDRmql",
        "outputId": "da6cd747-45d1-4a1f-ac38-09a935797035"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ–¼ï¸ ì´ ì´ë¯¸ì§€ ìˆ˜: 25000ì¥\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# VGG ì¸ì½”ë”"
      ],
      "metadata": {
        "id": "_u1BN98RTGMG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# VGG-19 pretrained ëª¨ë¸ì—ì„œ featuresë§Œ ê°€ì ¸ì˜¤ê¸°\n",
        "vgg = models.vgg19(pretrained=True).features\n",
        "\n",
        "# relu1_1 ~ relu4_1ê¹Œì§€ ë ˆì´ì–´ ë¶„í• \n",
        "class Net(nn.Module):\n",
        "    def __init__(self, encoder):\n",
        "        super(Net, self).__init__()\n",
        "        enc_layers = list(encoder.children())\n",
        "\n",
        "        # relu1_1, relu2_1, relu3_1, relu4_1ê¹Œì§€ë§Œ ì‚¬ìš©\n",
        "        self.enc_1 = nn.Sequential(*enc_layers[:4])    # input -> relu1_1\n",
        "        self.enc_2 = nn.Sequential(*enc_layers[4:11])  # relu1_1 -> relu2_1\n",
        "        self.enc_3 = nn.Sequential(*enc_layers[11:18]) # relu2_1 -> relu3_1\n",
        "        self.enc_4 = nn.Sequential(*enc_layers[18:31]) # relu3_1 -> relu4_1\n",
        "\n",
        "        # encoder íŒŒë¼ë¯¸í„° ê³ ì •\n",
        "        for name in ['enc_1', 'enc_2', 'enc_3', 'enc_4']:\n",
        "            for param in getattr(self, name).parameters():\n",
        "                param.requires_grad = False\n",
        "\n",
        "    # ì¤‘ê°„ ê²°ê³¼ë“¤ (relu1_1 ~ relu4_1) ë°˜í™˜\n",
        "    def encode_with_intermediate(self, input):\n",
        "        results = [input]\n",
        "        for i in range(4):\n",
        "            func = getattr(self, f'enc_{i + 1}')\n",
        "            results.append(func(results[-1]))\n",
        "        return results[1:]  # input ì œì™¸í•œ ê²°ê³¼ë§Œ ë°˜í™˜\n",
        "\n",
        "    # relu4_1 ê²°ê³¼ë§Œ ë°˜í™˜\n",
        "    def encode(self, input):\n",
        "        for i in range(4):\n",
        "            input = getattr(self, f'enc_{i + 1}')(input)\n",
        "        return input\n",
        "\n",
        "# ë„¤íŠ¸ì›Œí¬ ê°ì²´ ìƒì„±\n",
        "net = Net(vgg).to('cuda' if torch.cuda.is_available() else 'cpu')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BNyUg_WHV_T8",
        "outputId": "b6866dcb-cde4-4dec-8828-8dd38a01393d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\" to /root/.cache/torch/hub/checkpoints/vgg19-dcbb9e9d.pth\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 548M/548M [00:08<00:00, 69.2MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ì´ë¯¸ì§€ ì „ì²˜ë¦¬\n",
        "\n",
        "# ì§§ì€ ë³€ ê¸¸ì´ ë³€ê²½\n",
        "class ResizeShortSide:\n",
        "    def __init__(self, size):\n",
        "        self.size = size\n",
        "\n",
        "    def __call__(self, img):\n",
        "        w, h = img.size\n",
        "        if w < h:\n",
        "            new_w = self.size\n",
        "            new_h = int(h * self.size / w)\n",
        "        else:\n",
        "            new_h = self.size\n",
        "            new_w = int(w * self.size / h)\n",
        "        return img.resize((new_w, new_h), Image.BICUBIC)\n",
        "\n",
        "# ì „ì²´ ì „ì²˜ë¦¬\n",
        "vgg_transform = transforms.Compose([\n",
        "    ResizeShortSide(512),\n",
        "    transforms.RandomCrop(256),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std =[0.229, 0.224, 0.225])\n",
        "])\n"
      ],
      "metadata": {
        "id": "kuH5afj9a2Bb"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# íŠ¹ì§• ì¶”ì¶œ\n",
        "\n",
        "# ì´ë¯¸ì§€ íŒŒì¼ í™•ì¸\n",
        "def is_image_file(filename):\n",
        "    return filename.lower().endswith(('jpg', 'jpeg', 'png'))\n",
        "\n",
        "# í•˜ìœ„ í´ë” í™•ì¸\n",
        "class ImageFolderDataset(Dataset):\n",
        "    def __init__(self, folder_path, transform, has_subfolders=True):\n",
        "        self.transform = transform\n",
        "        self.image_paths = []\n",
        "\n",
        "        if has_subfolders:\n",
        "            subfolders = [os.path.join(folder_path, d)\n",
        "                          for d in os.listdir(folder_path)\n",
        "                          if os.path.isdir(os.path.join(folder_path, d))]\n",
        "        else:\n",
        "            subfolders = [folder_path]\n",
        "\n",
        "        for subfolder in subfolders:\n",
        "            for fname in os.listdir(subfolder):\n",
        "                if is_image_file(fname):\n",
        "                    self.image_paths.append(os.path.join(subfolder, fname))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        path = self.image_paths[idx]\n",
        "        try:\n",
        "            image = Image.open(path).convert('RGB')\n",
        "            tensor = self.transform(image)\n",
        "            return tensor, path\n",
        "        except Exception as e:\n",
        "            print(f\"[ì˜¤ë¥˜] ì´ë¯¸ì§€ ë¡œë”© ì‹¤íŒ¨: {path}, ì˜¤ë¥˜: {e}\")\n",
        "            return None  # collate_fnì—ì„œ í•„í„°ë§ë¨\n",
        "\n",
        "# collate_fn ì •ì˜ (ì˜ˆì™¸ ì´ë¯¸ì§€ ë¬´ì‹œ)\n",
        "def safe_collate(batch):\n",
        "    batch = [b for b in batch if b is not None]\n",
        "    if not batch:\n",
        "        return None\n",
        "    return default_collate(batch)\n",
        "\n",
        "# íŠ¹ì§• ì¶”ì¶œ í•¨ìˆ˜ (ë°°ì¹˜ ê¸°ë°˜)\n",
        "def extract_features_batch(folder_path, transform, has_subfolders=True, batch_size=32, num_workers=2):\n",
        "    dataset = ImageFolderDataset(folder_path, transform, has_subfolders)\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False,\n",
        "                            num_workers=num_workers, collate_fn=safe_collate)\n",
        "\n",
        "    features = []\n",
        "    paths = []\n",
        "\n",
        "    for batch in tqdm(dataloader, desc=f\"Extracting features from {os.path.basename(folder_path)}\"):\n",
        "        if batch is None:\n",
        "            continue\n",
        "        inputs, img_paths = batch\n",
        "        inputs = inputs.to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            batch_features = net.encode(inputs)\n",
        "\n",
        "        features.extend(batch_features.cpu())\n",
        "        paths.extend(img_paths)\n",
        "\n",
        "    return features, paths"
      ],
      "metadata": {
        "id": "dDC-kgcHXhdq"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# í…ŒìŠ¤íŠ¸ìš© coco_test ë§Œë“¤ê¸°\n",
        "coco_dir = '/content/drive/MyDrive/Colab Notebooks/AIApp/images/coco'\n",
        "coco_test_dir = '/content/drive/MyDrive/Colab Notebooks/AIApp/images/coco_test'\n",
        "\n",
        "# os.makedirs(coco_test_dir, exist_ok=True)\n",
        "\n",
        "# image_files = sorted([\n",
        "#     f for f in os.listdir(coco_dir)\n",
        "#     if f.lower().endswith(('.jpg', '.jpeg', '.png'))\n",
        "# ])[:32]\n",
        "\n",
        "# # ë³µì‚¬ ì‹¤í–‰\n",
        "# for fname in image_files:\n",
        "#     src_path = os.path.join(coco_dir, fname)\n",
        "#     dst_path = os.path.join(coco_test_dir, fname)\n",
        "#     shutil.copy2(src_path, dst_path)\n",
        "\n",
        "# print(f\"{len(image_files)}ê°œ ì´ë¯¸ì§€ê°€ {coco_test_dir}ë¡œ ë³µì‚¬ë˜ì—ˆìŠµë‹ˆë‹¤.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TGIhllqMsFo0",
        "outputId": "aa8af19e-fcba-4f43-de16-c99716cb3819"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32ê°œ ì´ë¯¸ì§€ê°€ /content/drive/MyDrive/Colab Notebooks/AIApp/images/coco_testë¡œ ë³µì‚¬ë˜ì—ˆìŠµë‹ˆë‹¤.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ì¸ì½”ë”©(í…ŒìŠ¤íŠ¸ìš©)\n",
        "coco_test_features, coco_test_paths = extract_features_batch(coco_test_dir, vgg_transform, has_subfolders=False)\n",
        "coco_test_features[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NtjkS2pZTNS6",
        "outputId": "4643e88e-b5d7-48f2-d6e6-407c28b72cf8"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting features from coco_test: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.55s/it]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([512, 16, 16])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # ì¸ì½”ë”©(ì‹¤ì œ ì‚¬ìš©) - ì—„ì²­ ì˜¤ë˜ ê±¸ë¦¼\n",
        "# coco_dir = '/content/drive/MyDrive/Colab Notebooks/AIApp/images/coco'\n",
        "# wikiart_dir = '/content/drive/MyDrive/Colab Notebooks/AIApp/images/wikiart'\n",
        "\n",
        "# coco_features, coco_paths = extract_features_batch(coco_dir, vgg_transform, has_subfolders=False)\n",
        "# print(\"coco ì¸ì½”ë”© ë\")\n",
        "# wikiart_features, wikiart_paths = extract_features_batch(wikiart_dir, vgg_transform, has_subfolders=True)\n",
        "# print(\"wikiart ì¸ì½”ë”© ë\")\n"
      ],
      "metadata": {
        "id": "rc1RAmKWVkSB"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# í…ìŠ¤íŠ¸ í”¼ì³ ë³€í™˜"
      ],
      "metadata": {
        "id": "x3nI6CE_clNz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ëª¨ë¸ ì •ì˜ ë° ê°€ì¤‘ì¹˜ ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "num_classes = 4  # ê°ì • í´ë˜ìŠ¤ ìˆ˜\n",
        "# image_dir = '/content/drive/MyDrive/Colab Notebooks/AIApp/images/coco_test' # í…ŒìŠ¤íŠ¸ìš©\n",
        "image_dir = '/content/drive/MyDrive/Colab Notebooks/AIApp/images/coco' # ì‹¤ì œ ì‚¬ìš©\n",
        "\n",
        "# ëª¨ë¸ ì •ì˜ (í•™ìŠµ ë‹¹ì‹œì™€ ë™ì¼í•˜ê²Œ)\n",
        "model = models.resnet18(pretrained=False)\n",
        "in_features = model.fc.in_features\n",
        "model.fc = nn.Sequential(\n",
        "    nn.Dropout(0.3),\n",
        "    nn.Linear(in_features, num_classes)\n",
        ")\n",
        "model.load_state_dict(torch.load('/content/drive/MyDrive/Colab Notebooks/AIApp/best_emotion_model_0520.pth',\n",
        "                                 map_location=torch.device('cpu'))) # ì›ë˜ gpuë¡œ ë¶ˆëŸ¬ì™€ì•¼ë˜ëŠ”ë° ì§€ê¸ˆ gpu ëª» ì¨ì„œ ì„ì‹œë¡œ cpu\n",
        "model = model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# ì „ì²˜ë¦¬ ì •ì˜\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rd_Q1Lqe1HSp",
        "outputId": "7ac2b5e8-fe71-4cda-98f5-d14f20c68a71"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ì´ë¯¸ì§€ ì˜ˆì¸¡í•˜ì—¬ label_idx ì¶”ì¶œ\n",
        "predicted_indices = []\n",
        "\n",
        "image_paths = [os.path.join(image_dir, fname) for fname in os.listdir(image_dir)\n",
        "               if fname.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
        "\n",
        "for path in tqdm(image_paths):\n",
        "    image = Image.open(path).convert('RGB')\n",
        "    image = transform(image).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model(image)\n",
        "        _, pred = torch.max(output, 1)\n",
        "        predicted_indices.append(pred.item())\n",
        "\n",
        "preds_tensor = torch.tensor(predicted_indices)\n",
        "preds_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LPn9-epDDGeP",
        "outputId": "33436054-74f1-433a-e3a5-3727692fb5d7"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25000/25000 [1:03:21<00:00,  6.58it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([3, 2, 2,  ..., 2, 1, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ì„ë² ë”©, ì„ í˜• ë³€í™˜\n",
        "embedding_dim = 512\n",
        "\n",
        "# ì„ë² ë”© & ì„ í˜•ë³€í™˜ ì •ì˜\n",
        "class_embedding = nn.Embedding(num_classes, embedding_dim)\n",
        "linear = nn.Linear(embedding_dim, 512)\n",
        "\n",
        "# GPUì— ì˜¬ë¦¬ê¸° (ì„ íƒì‚¬í•­)\n",
        "class_embedding = class_embedding.to(device)\n",
        "linear = linear.to(device)\n",
        "\n",
        "# ë³€í™˜ ìˆ˜í–‰\n",
        "embedded = class_embedding(preds_tensor.to(device))\n",
        "final_output = linear(embedded)\n"
      ],
      "metadata": {
        "id": "cdXFQk45DOUl"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4Fv5qCvTHVHS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}